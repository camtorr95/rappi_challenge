{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappi Challenge - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lib Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "import os.path\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current version of imported libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Numpy version: {np.version.version}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Sci-kit learn version: {sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_data = pd.read_csv('orders.csv');\n",
    "orders_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taken = orders_data[\"taken\"].value_counts()\n",
    "taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_rate = orders_data[\"taken\"].value_counts(normalize=True)\n",
    "print(f'Taza de aprobación del {current_rate[1]}. {counts[1]} Aceptados de {total} órdenes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aux function for droping order_id and categorize store_id. It was assumed that the prefix of store_id up to \"end\" could give a hint on it's type. In the end, I took all store_id values through OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ids(data, end):\n",
    "    n_data = data\n",
    "    n_data[\"store_id\"] = data[\"store_id\"].apply(lambda x: str(x)[0: end])\n",
    "    n_data = n_data.drop(\"order_id\", axis=1)\n",
    "    \n",
    "    return n_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract cyclic features from the date field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_created_at(data):\n",
    "    n_data = data\n",
    "    \n",
    "    _datetime = n_data[\"created_at\"].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    \n",
    "    xmes = _datetime.dt.month.apply(lambda x: math.sin(2 * math.pi * x / 12))\n",
    "    ymes = _datetime.dt.month.apply(lambda x: math.cos(2 * math.pi * x / 12))\n",
    "    \n",
    "    avg_days_year = 365.2425\n",
    "    \n",
    "    xdia = _datetime.dt.dayofyear.apply(lambda x: math.sin(2 * math.pi * x / avg_days_year))\n",
    "    ydia = _datetime.dt.dayofyear.apply(lambda x: math.cos(2 * math.pi * x / avg_days_year))\n",
    "    \n",
    "    xsem = _datetime.dt.dayofweek.apply(lambda x: math.sin(2 * math.pi * x / 7))\n",
    "    ysem = _datetime.dt.dayofweek.apply(lambda x: math.cos(2 * math.pi * x / 7))\n",
    "    \n",
    "    xhora = _datetime.dt.hour.apply(lambda x: math.sin(2 * math.pi * x / 24))\n",
    "    yhora = _datetime.dt.hour.apply(lambda x: math.cos(2 * math.pi * x / 24))\n",
    "    \n",
    "    xmin = _datetime.dt.minute.apply(lambda x: math.sin(2 * math.pi * x / 60))\n",
    "    ymin = _datetime.dt.minute.apply(lambda x: math.cos(2 * math.pi * x / 60))\n",
    "    \n",
    "    n_columns = pd.concat([xmes, ymes, xdia, ydia, xsem, ysem, xhora, yhora, xmin, ymin], axis=1);\n",
    "    n_columns.columns = [\"xmes\", \"ymes\", \"xdia\", \"ydia\", \"xsem\", \"ysem\", \"xhora\", \"yhora\", \"xmin\", \"ymin\"]\n",
    "    \n",
    "    n_data = n_data.drop(\"created_at\", axis=1)\n",
    "    n_data = pd.concat([n_data, n_columns], axis=1)\n",
    "    \n",
    "    return n_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the OneHotEncoding and StandardScaler with the information from the training data. Additionally, it dumps them into pickle files for the api to load and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_scale(x_train, _dataset):\n",
    "    base_encode = _dataset[\"store_id\"].values.reshape(-1 ,1)\n",
    "    base_scale = x_train.drop([\"store_id\"], axis=1)\n",
    "    \n",
    "    _ohencoder = None\n",
    "    _stdscaler = None\n",
    "    \n",
    "    if(os.path.isfile(\"_encoder.pkl\")):\n",
    "        _ohencoder = pickle.load(open(\"_encoder.pkl\", \"rb\"))\n",
    "    else:\n",
    "        _ohencoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\").fit(base_encode)\n",
    "        pickle.dump(_ohencoder, open(\"_encoder.pkl\", \"wb\"))\n",
    "    \n",
    "    if(os.path.isfile(\"_scaler.pkl\")):\n",
    "        _stdscaler = pickle.load(open(\"_scaler.pkl\", \"rb\"))\n",
    "    else:\n",
    "        _stdscaler = StandardScaler().fit(base_scale)\n",
    "        pickle.dump(_stdscaler, open(\"_scaler.pkl\", \"wb\"))\n",
    "    \n",
    "    return _ohencoder, _stdscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing and cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies all the methods defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    store_id_limit = 10\n",
    "    prep_id = prepare_ids(orders_data, store_id_limit)\n",
    "    dataset = prepare_created_at(prep_id)\n",
    "    taken = dataset[\"taken\"]\n",
    "    dataset = dataset.drop(\"taken\", axis=1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, taken, test_size=0.3, stratify=taken)\n",
    "    \n",
    "    ohencoder, stdscaler = encode_scale(x_train, dataset)\n",
    "    \n",
    "    x_train_ohe = ohencoder.transform(x_train[\"store_id\"].values.reshape(-1, 1))\n",
    "    x_train_std = stdscaler.transform(x_train.drop(\"store_id\", axis=1))\n",
    "    \n",
    "    x_train = pd.DataFrame(np.concatenate([x_train_ohe, x_train_std], axis=1))\n",
    "    \n",
    "    x_test_ohe = ohencoder.transform(x_test[\"store_id\"].values.reshape(-1, 1))\n",
    "    x_test_std = stdscaler.transform(x_test.drop(\"store_id\", axis=1))\n",
    "    \n",
    "    x_test = pd.DataFrame(np.concatenate([x_test_ohe, x_test_std], axis=1))\n",
    "    \n",
    "    return (ohencoder, stdscaler, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get's all the output from the preprocess method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohencoder, stdscaler, x_train, x_test, y_train, y_test = preprocess_data(orders_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling\n",
    "\n",
    "In the end training data was not upsampled for the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_train = y_train.values\n",
    "_y_train = pd.Series(_y_train, name=\"taken\")\n",
    "x_log_reg = x_train.join(_y_train)\n",
    "\n",
    "taken_0 = x_log_reg[x_log_reg[\"taken\"] == 0]\n",
    "taken_1 = x_log_reg[x_log_reg[\"taken\"] == 1]\n",
    "\n",
    "up_taken_0 = resample(taken_0, n_samples=taken_1.shape[0])\n",
    "# dw_taken_1 = resample(taken_1, n_samples=taken_0.shape[0])\n",
    "\n",
    "x_log_reg = pd.concat([up_taken_0, taken_1])\n",
    "# x_log_reg = pd.concat([taken_0, dw_taken_1])\n",
    "\n",
    "y_log_reg = x_log_reg[\"taken\"]\n",
    "x_log_reg = x_log_reg.drop(\"taken\", axis=1)\n",
    "\n",
    "x_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_class_weight={0: 0.9, 1: 0.1}\n",
    "log_reg = LogisticRegression(max_iter=50000, class_weight=_class_weight,\n",
    "                             C=1, solver='liblinear')\n",
    "\n",
    "log_reg.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy can improve with more exact class weights at the cost of ROC AUC, which could indicate overfitting. It was deliberately left like this, in favor of a higher ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(x_test.values)\n",
    "\n",
    "print(f'Score: {log_reg.score(x_test.values, y_test.values)}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test.values, y_pred)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test.values, y_pred)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test.values, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test.values, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_forest = RandomForestClassifier(class_weight=_class_weight)\n",
    "# rnd_forest.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to completely overfit the model. High accuracy, log ROC AUC. ends up with a pickle file size of 200+ MB if no max_depth is specified, which makes the logistic_regression approach more worth using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "y_pred = rnd_forest.predict(x_test.values)\n",
    "\n",
    "print(f'Score: {rnd_forest.score(x_test.values, y_test.values)}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test.values, y_pred)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test.values, y_pred)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test.values, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test.values, y_pred)}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models():\n",
    "    pickle.dump(log_reg, open(\"_log_reg.pkl\", \"wb\"))\n",
    "    # pickle.dump(rnd_forest, open(\"_rnd_forest.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eval(dataset, ohencoder, stdscaler):\n",
    "    store_id_limit = 10\n",
    "    prep_id = prepare_ids(dataset, store_id_limit)\n",
    "    dataset = prepare_created_at(prep_id)\n",
    "    taken = dataset[\"taken\"]\n",
    "    dataset = dataset.drop(\"taken\", axis=1)\n",
    "    \n",
    "    base_encode = dataset[\"store_id\"]\n",
    "    base_scale = dataset.drop(\"store_id\", axis=1)\n",
    "    \n",
    "    x_eval_ohe = ohencoder.transform(base_encode.values.reshape(-1, 1))\n",
    "    x_eval_std = stdscaler.transform(base_scale)\n",
    "    \n",
    "    x_eval = pd.DataFrame(np.concatenate([x_eval_ohe, x_eval_std], axis=1))\n",
    "    \n",
    "    return x_eval, taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval, y_eval = prepare_eval(orders_data, ohencoder, stdscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict(x_eval).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
